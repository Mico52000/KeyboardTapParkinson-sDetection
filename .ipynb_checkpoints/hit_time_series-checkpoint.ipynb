{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "705d3abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import nqDataLoader as nq #data loading library\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a7affcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pID</th>\n",
       "      <th>gt</th>\n",
       "      <th>updrs108</th>\n",
       "      <th>afTap</th>\n",
       "      <th>sTap</th>\n",
       "      <th>nqScore</th>\n",
       "      <th>typingSpeed</th>\n",
       "      <th>file_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>79.0</td>\n",
       "      <td>184.5</td>\n",
       "      <td>0.107179</td>\n",
       "      <td>56.866667</td>\n",
       "      <td>1424946827.1000_001_014.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>96.5</td>\n",
       "      <td>189.0</td>\n",
       "      <td>0.056286</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>1427279751.1001_001_014.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1002</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>140.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>0.039519</td>\n",
       "      <td>119.037037</td>\n",
       "      <td>1426676689.1002_001_014.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1004</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>83.5</td>\n",
       "      <td>191.5</td>\n",
       "      <td>0.034853</td>\n",
       "      <td>74.266667</td>\n",
       "      <td>1429866367.1004_001_014.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1005</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>68.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.048307</td>\n",
       "      <td>74.969697</td>\n",
       "      <td>1430134526.1005_001_014.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    pID  gt  updrs108  afTap   sTap   nqScore  typingSpeed  \\\n",
       "0  1000   1        27   79.0  184.5  0.107179    56.866667   \n",
       "1  1001   1        16   96.5  189.0  0.056286   118.000000   \n",
       "2  1002   0         5  140.0  158.0  0.039519   119.037037   \n",
       "3  1004   1        22   83.5  191.5  0.034853    74.266667   \n",
       "4  1005   1        17   68.0  150.0  0.048307    74.969697   \n",
       "\n",
       "                        file_1  \n",
       "0  1424946827.1000_001_014.csv  \n",
       "1  1427279751.1001_001_014.csv  \n",
       "2  1426676689.1002_001_014.csv  \n",
       "3  1429866367.1004_001_014.csv  \n",
       "4  1430134526.1005_001_014.csv  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## importing the early stage dataset \n",
    "early_stage = pd.read_csv('GT_DataPD_MIT-CS2PD.csv')\n",
    "# X = dataset.iloc[:, :-1].values\n",
    "# y = dataset.iloc[:, -1].values\n",
    "early_stage[\"gt\"] = early_stage[\"gt\"].astype(int)\n",
    "early_stage.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ea5e941",
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_time_series = []\n",
    "for index, row in early_stage.iterrows():\n",
    "    fileloc = row.file_1\n",
    "    keyPressed, htArr, pressArr, releaseArr =  nq.getDataFiltHelper( \"data_MIT-CS2PD/\" + early_stage.loc[index]['file_1'])\n",
    "    htArr =np.array(htArr)\n",
    "    hit_time_series.append(htArr)\n",
    "\n",
    "X1 = hit_time_series "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f32abeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pID</th>\n",
       "      <th>gt</th>\n",
       "      <th>updrs108</th>\n",
       "      <th>afTap</th>\n",
       "      <th>sTap</th>\n",
       "      <th>nqScore</th>\n",
       "      <th>typingSpeed</th>\n",
       "      <th>file_1</th>\n",
       "      <th>file_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>14.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162.25</td>\n",
       "      <td>0.117543</td>\n",
       "      <td>189.372549</td>\n",
       "      <td>1402930351.011_001_014.csv</td>\n",
       "      <td>1403706430.011_003_014.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162.25</td>\n",
       "      <td>0.070350</td>\n",
       "      <td>60.533333</td>\n",
       "      <td>1402932300.060_001_014.csv</td>\n",
       "      <td>1403708258.060_003_014.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>25.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>133.75</td>\n",
       "      <td>0.223411</td>\n",
       "      <td>54.333333</td>\n",
       "      <td>1401117235.067_001_014.csv</td>\n",
       "      <td>1401978395.067_003_014.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>159.00</td>\n",
       "      <td>0.074973</td>\n",
       "      <td>71.800000</td>\n",
       "      <td>1401114972.068_001_014.csv</td>\n",
       "      <td>1401980765.068_003_014.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>26.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>113.50</td>\n",
       "      <td>0.175751</td>\n",
       "      <td>39.614035</td>\n",
       "      <td>1404311419.070_001_014.csv</td>\n",
       "      <td>1404743687.070_003_014.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pID  gt  updrs108  afTap    sTap   nqScore  typingSpeed  \\\n",
       "0   11   1     14.25    NaN  162.25  0.117543   189.372549   \n",
       "1   60   0      2.00    NaN  162.25  0.070350    60.533333   \n",
       "2   67   1     25.25    NaN  133.75  0.223411    54.333333   \n",
       "3   68   0      6.00    NaN  159.00  0.074973    71.800000   \n",
       "4   70   1     26.25    NaN  113.50  0.175751    39.614035   \n",
       "\n",
       "                       file_1                      file_2  \n",
       "0  1402930351.011_001_014.csv  1403706430.011_003_014.csv  \n",
       "1  1402932300.060_001_014.csv  1403708258.060_003_014.csv  \n",
       "2  1401117235.067_001_014.csv  1401978395.067_003_014.csv  \n",
       "3  1401114972.068_001_014.csv  1401980765.068_003_014.csv  \n",
       "4  1404311419.070_001_014.csv  1404743687.070_003_014.csv  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## importing the de-novo dataset \n",
    "de_novo = pd.read_csv('GT_DataPD_MIT-CS1PD.csv')\n",
    "# X = dataset.iloc[:, :-1].values\n",
    "# y = dataset.iloc[:, -1].values\n",
    "print(len(de_novo))\n",
    "de_novo[\"gt\"] = de_novo[\"gt\"].astype(int)\n",
    "de_novo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5259add3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##using both files \n",
    "hit_time_series = []\n",
    "for index, row in de_novo.iterrows():\n",
    "    fileloc1 = row.file_1\n",
    "    keyPressed, htArr1, pressArr, releaseArr =  nq.getDataFiltHelper( 'data_MIT-CS1PD/' + de_novo.loc[index]['file_1'])\n",
    "    htArr1 = np.array(htArr1)\n",
    "    keyPressed, htArr2, pressArr, releaseArr =  nq.getDataFiltHelper( 'data_MIT-CS1PD/' + de_novo.loc[index]['file_2'])\n",
    "    htArr2 = np.array(htArr2)\n",
    "    htArr =np.concatenate((htArr1,htArr2),axis =0)\n",
    "    htArr=np.array(htArr)\n",
    "    hit_time_series.append(htArr)\n",
    "X2 = hit_time_series "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "427a9cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:180: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    }
   ],
   "source": [
    "X = np.concatenate((X1,X2),axis=0)\n",
    "min = len(X[0])\n",
    "for i,e in enumerate(X):\n",
    "    if len(e)<min:\n",
    "        min = len(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "91950d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85 85\n",
      "[[0.3179 0.1892 0.1641 ... 0.1465 0.15   0.1036]\n",
      " [0.1135 0.1269 0.1317 ... 0.1877 0.1673 0.0964]\n",
      " [0.0619 0.0598 0.1309 ... 0.0533 0.0704 0.0728]\n",
      " ...\n",
      " [0.2817 0.1244 0.1983 ... 0.1237 0.1726 0.1084]\n",
      " [0.1759 0.1583 0.293  ... 0.1244 0.068  0.0625]\n",
      " [0.1122 0.0822 0.0872 ... 0.0995 0.0674 0.0772]]\n",
      "[1 1 0 1 1 1 1 1 0 0 0 0 1 0 0 1 1 1 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0 1 0 0 0\n",
      " 1 0 0 0 1 0 0 0 0 1 0 0 0 1 1 1 0 1 0 1 0 1 1 1 1 1 1 0 0 1 0 1 0 1 0 1 0\n",
      " 1 0 1 0 1 1 0 0 1 1 0]\n",
      "(85, 299)\n"
     ]
    }
   ],
   "source": [
    "X =sequence.pad_sequences(X,dtype='float32',truncating='post',maxlen=min) \n",
    "y=  np.concatenate((early_stage['gt'],de_novo[\"gt\"]),axis=0)\n",
    "print(len(X),len(y))\n",
    "print(X)\n",
    "print(y)\n",
    "print(np.shape(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6c5c7890",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    " \n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    \"\"\"\n",
    "    Frame a time series as a supervised learning dataset.\n",
    "    Arguments:\n",
    "        data: Sequence of observations as a list or NumPy array.\n",
    "        n_in: Number of lag observations as input (X).\n",
    "        n_out: Number of observations as output (y).\n",
    "        dropnan: Boolean whether or not to drop rows with NaN values.\n",
    "    Returns:\n",
    "        Pandas DataFrame of series framed for supervised learning.\n",
    "    \"\"\"\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "622a0aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ed0794f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.16885553]\n",
      "  [0.18400244]\n",
      "  [0.11916806]\n",
      "  ...\n",
      "  [0.24943207]\n",
      "  [0.5286116 ]\n",
      "  [0.7199271 ]]\n",
      "\n",
      " [[0.46491557]\n",
      "  [0.44920927]\n",
      "  [0.35188305]\n",
      "  ...\n",
      "  [0.48523396]\n",
      "  [0.44136953]\n",
      "  [0.38031593]]\n",
      "\n",
      " [[0.1084428 ]\n",
      "  [0.111618  ]\n",
      "  [0.22062956]\n",
      "  ...\n",
      "  [0.13811903]\n",
      "  [0.34943712]\n",
      "  [0.03037667]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.7249531 ]\n",
      "  [1.        ]\n",
      "  [0.7121979 ]\n",
      "  ...\n",
      "  [0.8818719 ]\n",
      "  [1.        ]\n",
      "  [0.3748481 ]]\n",
      "\n",
      " [[0.12345214]\n",
      "  [0.10249393]\n",
      "  [0.00337268]\n",
      "  ...\n",
      "  [0.18355294]\n",
      "  [0.24530955]\n",
      "  [0.49696234]]\n",
      "\n",
      " [[0.22701691]\n",
      "  [0.30018246]\n",
      "  [0.8265879 ]\n",
      "  ...\n",
      "  [0.99999994]\n",
      "  [0.7847091 ]\n",
      "  [0.5164033 ]]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range=(0,1))\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1],1))\n",
    "print(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accfced1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc816cc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 299, 50)           10400     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 299, 50)           0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 50)                20200     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30,651\n",
      "Trainable params: 30,651\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 5s 195ms/step - loss: 0.6956 - accuracy: 0.4559\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 3s 191ms/step - loss: 0.6833 - accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 3s 188ms/step - loss: 0.6717 - accuracy: 0.5147\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 3s 188ms/step - loss: 0.6857 - accuracy: 0.5882\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 3s 191ms/step - loss: 0.6705 - accuracy: 0.6471\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 3s 186ms/step - loss: 0.6542 - accuracy: 0.6471\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 3s 195ms/step - loss: 0.6406 - accuracy: 0.6618\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 3s 188ms/step - loss: 0.6244 - accuracy: 0.6618\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 3s 191ms/step - loss: 0.6193 - accuracy: 0.6765\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 3s 189ms/step - loss: 0.6463 - accuracy: 0.6618\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 3s 185ms/step - loss: 0.6275 - accuracy: 0.7059\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 3s 191ms/step - loss: 0.6289 - accuracy: 0.6471\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 3s 188ms/step - loss: 0.6375 - accuracy: 0.6471\n",
      "Epoch 14/100\n",
      "14/14 [==============================] - 3s 188ms/step - loss: 0.6161 - accuracy: 0.6471\n",
      "Epoch 15/100\n",
      "14/14 [==============================] - 3s 191ms/step - loss: 0.6175 - accuracy: 0.6471\n",
      "Epoch 16/100\n",
      "14/14 [==============================] - 3s 189ms/step - loss: 0.6305 - accuracy: 0.6765\n",
      "Epoch 17/100\n",
      "14/14 [==============================] - 3s 193ms/step - loss: 0.6235 - accuracy: 0.6471\n",
      "Epoch 18/100\n",
      "14/14 [==============================] - 3s 189ms/step - loss: 0.6243 - accuracy: 0.6471\n",
      "Epoch 19/100\n",
      "14/14 [==============================] - 3s 191ms/step - loss: 0.6280 - accuracy: 0.6471\n",
      "Epoch 20/100\n",
      "14/14 [==============================] - 3s 202ms/step - loss: 0.6076 - accuracy: 0.6471\n",
      "Epoch 21/100\n",
      "14/14 [==============================] - 3s 189ms/step - loss: 0.6029 - accuracy: 0.6618\n",
      "Epoch 22/100\n",
      "14/14 [==============================] - 3s 187ms/step - loss: 0.6150 - accuracy: 0.6471\n",
      "Epoch 23/100\n",
      "14/14 [==============================] - 3s 187ms/step - loss: 0.6224 - accuracy: 0.6618\n",
      "Epoch 24/100\n",
      "14/14 [==============================] - 3s 190ms/step - loss: 0.6152 - accuracy: 0.6765\n",
      "Epoch 25/100\n",
      "14/14 [==============================] - 3s 192ms/step - loss: 0.6239 - accuracy: 0.6471\n",
      "Epoch 26/100\n",
      "14/14 [==============================] - 3s 186ms/step - loss: 0.6081 - accuracy: 0.6618\n",
      "Epoch 27/100\n",
      "14/14 [==============================] - 3s 189ms/step - loss: 0.6032 - accuracy: 0.6618\n",
      "Epoch 28/100\n",
      "14/14 [==============================] - 3s 187ms/step - loss: 0.6129 - accuracy: 0.6471\n",
      "Epoch 29/100\n",
      "14/14 [==============================] - 3s 190ms/step - loss: 0.6073 - accuracy: 0.6765\n",
      "Epoch 30/100\n",
      "14/14 [==============================] - 3s 190ms/step - loss: 0.6264 - accuracy: 0.6471\n",
      "Epoch 31/100\n",
      "14/14 [==============================] - 3s 192ms/step - loss: 0.6083 - accuracy: 0.6471\n",
      "Epoch 32/100\n",
      "14/14 [==============================] - 3s 199ms/step - loss: 0.6108 - accuracy: 0.6618\n",
      "Epoch 33/100\n",
      "14/14 [==============================] - 3s 186ms/step - loss: 0.5930 - accuracy: 0.6618\n",
      "Epoch 34/100\n",
      "14/14 [==============================] - 3s 193ms/step - loss: 0.6295 - accuracy: 0.6765\n",
      "Epoch 35/100\n",
      " 5/14 [=========>....................] - ETA: 1s - loss: 0.5301 - accuracy: 0.7200"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "clf = Sequential()\n",
    "clf.add(LSTM(units = 100,return_sequences = True, input_shape = (X_train.shape[1], X_train.shape[2])))\n",
    "clf.add(Dropout(0.2))\n",
    "clf.add(LSTM(units = 100,return_sequences = True)\n",
    "clf.add(Dropout(0.2))\n",
    "clf.add(LSTM(units = 100))\n",
    "clf.add(Dropout(0.2))\n",
    "clf.add(Dense(units = 1,activation='sigmoid'))\n",
    "clf.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(clf.summary())\n",
    "clf.fit(X_train, y_train, epochs=100, batch_size=5)\n",
    "scores = clf.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
