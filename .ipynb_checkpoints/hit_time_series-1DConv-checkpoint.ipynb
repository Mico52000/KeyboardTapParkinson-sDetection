{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "705d3abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import nqDataLoader as nq #data loading library\n",
    "from keras.preprocessing import sequence\n",
    "# np.random.seed(0)\n",
    "# cnn model\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack\n",
    "from matplotlib import pyplot\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "# from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6a7affcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pID</th>\n",
       "      <th>gt</th>\n",
       "      <th>updrs108</th>\n",
       "      <th>afTap</th>\n",
       "      <th>sTap</th>\n",
       "      <th>nqScore</th>\n",
       "      <th>typingSpeed</th>\n",
       "      <th>file_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>79.0</td>\n",
       "      <td>184.5</td>\n",
       "      <td>0.107179</td>\n",
       "      <td>56.866667</td>\n",
       "      <td>1424946827.1000_001_014.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>96.5</td>\n",
       "      <td>189.0</td>\n",
       "      <td>0.056286</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>1427279751.1001_001_014.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1002</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>140.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>0.039519</td>\n",
       "      <td>119.037037</td>\n",
       "      <td>1426676689.1002_001_014.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1004</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>83.5</td>\n",
       "      <td>191.5</td>\n",
       "      <td>0.034853</td>\n",
       "      <td>74.266667</td>\n",
       "      <td>1429866367.1004_001_014.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1005</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>68.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.048307</td>\n",
       "      <td>74.969697</td>\n",
       "      <td>1430134526.1005_001_014.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    pID  gt  updrs108  afTap   sTap   nqScore  typingSpeed  \\\n",
       "0  1000   1        27   79.0  184.5  0.107179    56.866667   \n",
       "1  1001   1        16   96.5  189.0  0.056286   118.000000   \n",
       "2  1002   0         5  140.0  158.0  0.039519   119.037037   \n",
       "3  1004   1        22   83.5  191.5  0.034853    74.266667   \n",
       "4  1005   1        17   68.0  150.0  0.048307    74.969697   \n",
       "\n",
       "                        file_1  \n",
       "0  1424946827.1000_001_014.csv  \n",
       "1  1427279751.1001_001_014.csv  \n",
       "2  1426676689.1002_001_014.csv  \n",
       "3  1429866367.1004_001_014.csv  \n",
       "4  1430134526.1005_001_014.csv  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## importing the early stage dataset \n",
    "early_stage = pd.read_csv('GT_DataPD_MIT-CS2PD.csv')\n",
    "# X = dataset.iloc[:, :-1].values\n",
    "# y = dataset.iloc[:, -1].values\n",
    "early_stage[\"gt\"] = early_stage[\"gt\"].astype(int)\n",
    "early_stage.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1ea5e941",
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_time_series = []\n",
    "for index, row in early_stage.iterrows():\n",
    "    fileloc = row.file_1\n",
    "    keyPressed, htArr, pressArr, releaseArr =  nq.getDataFiltHelper( \"data_MIT-CS2PD/\" + early_stage.loc[index]['file_1'])\n",
    "    htArr =np.array(htArr)\n",
    "    hit_time_series.append(htArr)\n",
    "\n",
    "X1 = hit_time_series "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6f32abeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pID</th>\n",
       "      <th>gt</th>\n",
       "      <th>updrs108</th>\n",
       "      <th>afTap</th>\n",
       "      <th>sTap</th>\n",
       "      <th>nqScore</th>\n",
       "      <th>typingSpeed</th>\n",
       "      <th>file_1</th>\n",
       "      <th>file_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>14.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162.25</td>\n",
       "      <td>0.117543</td>\n",
       "      <td>189.372549</td>\n",
       "      <td>1402930351.011_001_014.csv</td>\n",
       "      <td>1403706430.011_003_014.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162.25</td>\n",
       "      <td>0.070350</td>\n",
       "      <td>60.533333</td>\n",
       "      <td>1402932300.060_001_014.csv</td>\n",
       "      <td>1403708258.060_003_014.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>25.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>133.75</td>\n",
       "      <td>0.223411</td>\n",
       "      <td>54.333333</td>\n",
       "      <td>1401117235.067_001_014.csv</td>\n",
       "      <td>1401978395.067_003_014.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>159.00</td>\n",
       "      <td>0.074973</td>\n",
       "      <td>71.800000</td>\n",
       "      <td>1401114972.068_001_014.csv</td>\n",
       "      <td>1401980765.068_003_014.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>26.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>113.50</td>\n",
       "      <td>0.175751</td>\n",
       "      <td>39.614035</td>\n",
       "      <td>1404311419.070_001_014.csv</td>\n",
       "      <td>1404743687.070_003_014.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pID  gt  updrs108  afTap    sTap   nqScore  typingSpeed  \\\n",
       "0   11   1     14.25    NaN  162.25  0.117543   189.372549   \n",
       "1   60   0      2.00    NaN  162.25  0.070350    60.533333   \n",
       "2   67   1     25.25    NaN  133.75  0.223411    54.333333   \n",
       "3   68   0      6.00    NaN  159.00  0.074973    71.800000   \n",
       "4   70   1     26.25    NaN  113.50  0.175751    39.614035   \n",
       "\n",
       "                       file_1                      file_2  \n",
       "0  1402930351.011_001_014.csv  1403706430.011_003_014.csv  \n",
       "1  1402932300.060_001_014.csv  1403708258.060_003_014.csv  \n",
       "2  1401117235.067_001_014.csv  1401978395.067_003_014.csv  \n",
       "3  1401114972.068_001_014.csv  1401980765.068_003_014.csv  \n",
       "4  1404311419.070_001_014.csv  1404743687.070_003_014.csv  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## importing the de-novo dataset \n",
    "de_novo = pd.read_csv('GT_DataPD_MIT-CS1PD.csv')\n",
    "# X = dataset.iloc[:, :-1].values\n",
    "# y = dataset.iloc[:, -1].values\n",
    "print(len(de_novo))\n",
    "de_novo[\"gt\"] = de_novo[\"gt\"].astype(int)\n",
    "de_novo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5259add3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##using both files \n",
    "hit_time_series = []\n",
    "for index, row in de_novo.iterrows():\n",
    "    fileloc1 = row.file_1\n",
    "    keyPressed, htArr1, pressArr, releaseArr =  nq.getDataFiltHelper( 'data_MIT-CS1PD/' + de_novo.loc[index]['file_1'])\n",
    "    htArr1 = np.array(htArr1)\n",
    "    keyPressed, htArr2, pressArr, releaseArr =  nq.getDataFiltHelper( 'data_MIT-CS1PD/' + de_novo.loc[index]['file_2'])\n",
    "    htArr2 = np.array(htArr2)\n",
    "    htArr =np.concatenate((htArr1,htArr2),axis =0)\n",
    "    htArr=np.array(htArr)\n",
    "    hit_time_series.append(htArr)\n",
    "X2 = hit_time_series "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6e96882f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(85,)\n",
      "[1 1 0 1 1 1 1 1 0 0 0 0 1 0 0 1 1 1 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0 1 0 0 0\n",
      " 1 0 0 0 1 0 0 0 0 1 0 0 0 1 1 1 0 1 0 1 0 1 1 1 1 1 1 0 0 1 0 1 0 1 0 1 0\n",
      " 1 0 1 0 1 1 0 0 1 1 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:180: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    }
   ],
   "source": [
    "X = np.concatenate((X1,X2),axis=0)\n",
    "y=  np.concatenate((early_stage['gt'],de_novo[\"gt\"]),axis=0)\n",
    "print(X.shape)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "91950d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11633377817478088\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "from sklearn.model_selection import train_test_split\n",
    "flat_list = list(itertools.chain(*X))\n",
    "value = sum(flat_list) / len(flat_list)\n",
    "print(value)\n",
    "X_padded =sequence.pad_sequences(X,dtype='float32',padding='post',maxlen=6000,value =0)\n",
    "\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_3D,y,test_size=0.17,random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3293b709",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def evaluate_model(trainX, trainy, testX, testy):\n",
    "    verbose, epochs, batch_size = 0, 10, 32\n",
    "    n_timesteps, n_features = trainX.shape[1], trainX.shape[2]\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(n_timesteps,n_features)))\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(1, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # fit network\n",
    "    model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    # evaluate model\n",
    "    _, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "af1b3067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x000001AFD7E2E440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.46666666865348816"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "622a0aa1",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\numpy\\core\\fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bound(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [60]\u001b[0m, in \u001b[0;36m<cell line: 28>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m%.3f\u001b[39;00m\u001b[38;5;132;01m%%\u001b[39;00m\u001b[38;5;124m (+/-\u001b[39m\u001b[38;5;132;01m%.3f\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (m, s)) \n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# run the experiment\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [60]\u001b[0m, in \u001b[0;36mrun_experiment\u001b[1;34m(repeats)\u001b[0m\n\u001b[0;32m      8\u001b[0m sc \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[0;32m      9\u001b[0m trainX \u001b[38;5;241m=\u001b[39m sc\u001b[38;5;241m.\u001b[39mfit_transform(trainX)\n\u001b[1;32m---> 10\u001b[0m trainX \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainX\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrainX\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m testX \u001b[38;5;241m=\u001b[39m sc\u001b[38;5;241m.\u001b[39mtransform(testX)\n\u001b[0;32m     12\u001b[0m testX \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreshape(testX,(testX[\u001b[38;5;241m0\u001b[39m],testX[\u001b[38;5;241m1\u001b[39m],\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mreshape\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\numpy\\core\\fromnumeric.py:298\u001b[0m, in \u001b[0;36mreshape\u001b[1;34m(a, newshape, order)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_reshape_dispatcher)\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreshape\u001b[39m(a, newshape, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;124;03m    Gives a new shape to an array without changing its data.\u001b[39;00m\n\u001b[0;32m    202\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;124;03m           [5, 6]])\u001b[39;00m\n\u001b[0;32m    297\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreshape\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\numpy\\core\\fromnumeric.py:66\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bound(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[1;32m---> 66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\numpy\\core\\fromnumeric.py:43\u001b[0m, in \u001b[0;36m_wrapit\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[0;32m     42\u001b[0m     wrap \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(asarray(obj), method)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wrap:\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, mu\u001b[38;5;241m.\u001b[39mndarray):\n",
      "\u001b[1;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# run an experiment\n",
    "def run_experiment(repeats=10):\n",
    "    # load data\n",
    "    trainX,testX,trainy,testy = train_test_split(X_padded,y,test_size=0.17)\n",
    "    trainX = np.array(trainX)\n",
    "    testX = np.array(testX)\n",
    "    sc = StandardScaler()\n",
    "    trainX = sc.fit_transform(trainX)\n",
    "    trainX = np.reshape(trainX,(trainX.shape[0],trainX.shape[1],1))\n",
    "    testX = sc.transform(testX)\n",
    "    testX = np.reshape(testX,(testX.shape[0],testX.shape[1],1))\n",
    "    # repeat experiment\n",
    "    scores = list()\n",
    "    for r in range(repeats):\n",
    "        score = evaluate_model(trainX, trainy, testX, testy)\n",
    "        score = score * 100.0\n",
    "        print('>#%d: %.3f' % (r+1, score))\n",
    "        scores.append(score)\n",
    "    # summarize results\n",
    "    summarize_results(scores)\n",
    "# summarize scores\n",
    "def summarize_results(scores):\n",
    "    print(scores)\n",
    "    m, s = mean(scores), std(scores)\n",
    "    print('Accuracy: %.3f%% (+/-%.3f)' % (m, s)) \n",
    "# run the experiment\n",
    "run_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c51390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a histogram of each variable in the dataset\n",
    "def plot_variable_distributions(trainX):\n",
    "    pyplot.figure()\n",
    "    xaxis = None\n",
    "    for i in range(trainX.shape[1]):\n",
    "        ax = pyplot.subplot(trainX.shape[1], 1, i+1, sharex=xaxis)\n",
    "        ax.set_xlim(-1, 1)\n",
    "        if i == 0:\n",
    "            xaxis = ax\n",
    "        pyplot.hist(trainX[:, i], bins=100)\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41afdac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_variable_distributions(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269bc5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "X_train = sc.fit_transform(X_train)\n",
    "\n",
    "\n",
    "\n",
    "X_test = sc.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e507c9db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc816cc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense\n",
    "# from keras.layers import LSTM\n",
    "# from keras.layers import Dropout\n",
    "# from keras.callbacks import EarlyStopping\n",
    "# from matplotlib import pyplot\n",
    "# from keras import optimizers\n",
    "# import tensorflow as tf\n",
    "# clf = Sequential()\n",
    "# clf.add(LSTM(units = 30,return_sequences = True, input_shape = (X_train.shape[1], X_train.shape[2])))\n",
    "# clf.add(Dropout(0.2))\n",
    "# clf.add(LSTM(units = 30,return_sequences = True))\n",
    "# clf.add(Dropout(0.2))\n",
    "# clf.add(LSTM(units = 30,return_sequences = True))\n",
    "# clf.add(Dropout(0.2))\n",
    "# clf.add(LSTM(units =30 ))\n",
    "# clf.add(Dropout(0.2))\n",
    "# clf.add(Dense(units = 1,activation='sigmoid'))\n",
    "# es = EarlyStopping(monitor='loss', mode='auto', patience =50 ,verbose=1,restore_best_weights=True)\n",
    "# adm = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "# clf.compile(loss='binary_crossentropy', optimizer=adm, metrics=['accuracy'])\n",
    "# print(clf.summary())\n",
    "# history=clf.fit(X_train, y_train, epochs=200, batch_size=35)\n",
    "# scores = clf.evaluate(X_test, y_test, verbose=0)\n",
    "# print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "# train_acc = clf.evaluate(X_train, y_train, verbose=0)\n",
    "# test_acc = clf.evaluate(X_test, y_test, verbose=0)\n",
    "# print('Train: %.3f, Test: %.3f' % (train_acc[1], test_acc[1]))\n",
    "# # plot training history\n",
    "# pyplot.plot(history.history['loss'], label='train loss')\n",
    "# pyplot.plot(history.history['accuracy'], label='train accuracy')\n",
    "# # pyplot.plot(history.history['val_loss'], label='test')\n",
    "# pyplot.legend()\n",
    "# pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
