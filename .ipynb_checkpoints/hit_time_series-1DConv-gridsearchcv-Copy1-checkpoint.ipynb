{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "705d3abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import nqDataLoader as nq #data loading library\n",
    "from keras.preprocessing import sequence\n",
    "# np.random.seed(0)\n",
    "# cnn model\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "# from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b187bc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpus = tf.config.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#   # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n",
    "#   try:\n",
    "#     tf.config.set_logical_device_configuration(\n",
    "#         gpus[0],\n",
    "#         [tf.config.LogicalDeviceConfiguration(memory_limit=4096)])\n",
    "#     logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "#     print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "#   except RuntimeError as e:\n",
    "#     # Virtual devices must be set before GPUs have been initialized\n",
    "#     print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be05115f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13156c3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available(cuda_only=False, min_cuda_compute_capability=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8227607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from numba import cuda \n",
    "# device = cuda.get_current_device()\n",
    "# device.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a7affcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pID</th>\n",
       "      <th>gt</th>\n",
       "      <th>updrs108</th>\n",
       "      <th>afTap</th>\n",
       "      <th>sTap</th>\n",
       "      <th>nqScore</th>\n",
       "      <th>typingSpeed</th>\n",
       "      <th>file_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>79.0</td>\n",
       "      <td>184.5</td>\n",
       "      <td>0.107179</td>\n",
       "      <td>56.866667</td>\n",
       "      <td>1424946827.1000_001_014.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>96.5</td>\n",
       "      <td>189.0</td>\n",
       "      <td>0.056286</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>1427279751.1001_001_014.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1002</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>140.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>0.039519</td>\n",
       "      <td>119.037037</td>\n",
       "      <td>1426676689.1002_001_014.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1004</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>83.5</td>\n",
       "      <td>191.5</td>\n",
       "      <td>0.034853</td>\n",
       "      <td>74.266667</td>\n",
       "      <td>1429866367.1004_001_014.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1005</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>68.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.048307</td>\n",
       "      <td>74.969697</td>\n",
       "      <td>1430134526.1005_001_014.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    pID  gt  updrs108  afTap   sTap   nqScore  typingSpeed  \\\n",
       "0  1000   1        27   79.0  184.5  0.107179    56.866667   \n",
       "1  1001   1        16   96.5  189.0  0.056286   118.000000   \n",
       "2  1002   0         5  140.0  158.0  0.039519   119.037037   \n",
       "3  1004   1        22   83.5  191.5  0.034853    74.266667   \n",
       "4  1005   1        17   68.0  150.0  0.048307    74.969697   \n",
       "\n",
       "                        file_1  \n",
       "0  1424946827.1000_001_014.csv  \n",
       "1  1427279751.1001_001_014.csv  \n",
       "2  1426676689.1002_001_014.csv  \n",
       "3  1429866367.1004_001_014.csv  \n",
       "4  1430134526.1005_001_014.csv  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## importing the early stage dataset \n",
    "early_stage = pd.read_csv('GT_DataPD_MIT-CS2PD.csv')\n",
    "# X = dataset.iloc[:, :-1].values\n",
    "# y = dataset.iloc[:, -1].values\n",
    "early_stage[\"gt\"] = early_stage[\"gt\"].astype(int)\n",
    "early_stage.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ea5e941",
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_time_series = []\n",
    "for index, row in early_stage.iterrows():\n",
    "    fileloc = row.file_1\n",
    "    keyPressed, htArr, pressArr, releaseArr =  nq.getDataFiltHelper( \"data_MIT-CS2PD/\" + early_stage.loc[index]['file_1'])\n",
    "    htArr =np.array(htArr)\n",
    "    hit_time_series.append(htArr)\n",
    "\n",
    "X1 = hit_time_series "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6f32abeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pID</th>\n",
       "      <th>gt</th>\n",
       "      <th>updrs108</th>\n",
       "      <th>afTap</th>\n",
       "      <th>sTap</th>\n",
       "      <th>nqScore</th>\n",
       "      <th>typingSpeed</th>\n",
       "      <th>file_1</th>\n",
       "      <th>file_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>14.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162.25</td>\n",
       "      <td>0.117543</td>\n",
       "      <td>189.372549</td>\n",
       "      <td>1402930351.011_001_014.csv</td>\n",
       "      <td>1403706430.011_003_014.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162.25</td>\n",
       "      <td>0.070350</td>\n",
       "      <td>60.533333</td>\n",
       "      <td>1402932300.060_001_014.csv</td>\n",
       "      <td>1403708258.060_003_014.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>25.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>133.75</td>\n",
       "      <td>0.223411</td>\n",
       "      <td>54.333333</td>\n",
       "      <td>1401117235.067_001_014.csv</td>\n",
       "      <td>1401978395.067_003_014.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>159.00</td>\n",
       "      <td>0.074973</td>\n",
       "      <td>71.800000</td>\n",
       "      <td>1401114972.068_001_014.csv</td>\n",
       "      <td>1401980765.068_003_014.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>26.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>113.50</td>\n",
       "      <td>0.175751</td>\n",
       "      <td>39.614035</td>\n",
       "      <td>1404311419.070_001_014.csv</td>\n",
       "      <td>1404743687.070_003_014.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pID  gt  updrs108  afTap    sTap   nqScore  typingSpeed  \\\n",
       "0   11   1     14.25    NaN  162.25  0.117543   189.372549   \n",
       "1   60   0      2.00    NaN  162.25  0.070350    60.533333   \n",
       "2   67   1     25.25    NaN  133.75  0.223411    54.333333   \n",
       "3   68   0      6.00    NaN  159.00  0.074973    71.800000   \n",
       "4   70   1     26.25    NaN  113.50  0.175751    39.614035   \n",
       "\n",
       "                       file_1                      file_2  \n",
       "0  1402930351.011_001_014.csv  1403706430.011_003_014.csv  \n",
       "1  1402932300.060_001_014.csv  1403708258.060_003_014.csv  \n",
       "2  1401117235.067_001_014.csv  1401978395.067_003_014.csv  \n",
       "3  1401114972.068_001_014.csv  1401980765.068_003_014.csv  \n",
       "4  1404311419.070_001_014.csv  1404743687.070_003_014.csv  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## importing the de-novo dataset \n",
    "de_novo = pd.read_csv('GT_DataPD_MIT-CS1PD.csv')\n",
    "# X = dataset.iloc[:, :-1].values\n",
    "# y = dataset.iloc[:, -1].values\n",
    "print(len(de_novo))\n",
    "de_novo[\"gt\"] = de_novo[\"gt\"].astype(int)\n",
    "de_novo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5259add3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##using both files \n",
    "hit_time_series = []\n",
    "for index, row in de_novo.iterrows():\n",
    "    fileloc1 = row.file_1\n",
    "    keyPressed, htArr1, pressArr, releaseArr =  nq.getDataFiltHelper( 'data_MIT-CS1PD/' + de_novo.loc[index]['file_1'])\n",
    "    htArr1 = np.array(htArr1)\n",
    "    keyPressed, htArr2, pressArr, releaseArr =  nq.getDataFiltHelper( 'data_MIT-CS1PD/' + de_novo.loc[index]['file_2'])\n",
    "    htArr2 = np.array(htArr2)\n",
    "    htArr =np.concatenate((htArr1,htArr2),axis =0)\n",
    "    htArr=np.array(htArr)\n",
    "    hit_time_series.append(htArr)\n",
    "X2 = hit_time_series "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0d6eb85f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(85,)\n",
      "[1 1 0 1 1 1 1 1 0 0 0 0 1 0 0 1 1 1 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0 1 0 0 0\n",
      " 1 0 0 0 1 0 0 0 0 1 0 0 0 1 1 1 0 1 0 1 0 1 1 1 1 1 1 0 0 1 0 1 0 1 0 1 0\n",
      " 1 0 1 0 1 1 0 0 1 1 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    }
   ],
   "source": [
    "X = np.concatenate((X1,X2),axis=0)\n",
    "y=  np.concatenate((early_stage['gt'],de_novo[\"gt\"]),axis=0)\n",
    "print(X.shape)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "91950d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11633377817478088\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "flat_list = list(itertools.chain(*X))\n",
    "value = sum(flat_list) / len(flat_list)\n",
    "print(value)\n",
    "X_padded =sequence.pad_sequences(X,dtype='float32',padding='post',maxlen=6000,value =1)\n",
    "\n",
    "# X_padded = np.log(X_padded)\n",
    "\n",
    "# sc = StandardScaler()\n",
    "# X_padded = sc.fit_transform(X_padded)\n",
    "# X_padded = np.reshape(X_padded,(85,6000,1))\n",
    "# X_train,X_test,y_train,y_test = train_test_split(X_padded,y,test_size=0.17,stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e4bca9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers.merge import concatenate\n",
    "def create_model(n_dense=50,dropout=0.5):\n",
    "    # head 1\n",
    "    inputs1 = Input(shape=(6000,1))\n",
    "    conv1 = Conv1D(filters=64, kernel_size=3, activation='relu')(inputs1)\n",
    "    drop1 = Dropout(dropout)(conv1)\n",
    "    pool1 = MaxPooling1D(pool_size=2)(drop1)\n",
    "    flat1 = Flatten()(pool1)\n",
    "#     # head 2\n",
    "#     inputs2 = Input(shape=(6000,1))\n",
    "#     conv2 = Conv1D(filters=256, kernel_size=3, activation='relu')(inputs2)\n",
    "#     drop2 = Dropout(dropout)(conv2)\n",
    "#     pool2 = MaxPooling1D(pool_size=2)(drop2)\n",
    "#     flat2 = Flatten()(pool2)\n",
    "    #head 3\n",
    "    inputs3 = Input(shape=(6000,1))\n",
    "    conv3 = Conv1D(filters= 64, kernel_size=5, activation='relu')(inputs3)\n",
    "    drop3 = Dropout(dropout)(conv3)\n",
    "    pool3 = MaxPooling1D(pool_size=2)(drop3)\n",
    "    flat3 = Flatten()(pool3)\n",
    "#     head 4\n",
    "    inputs4 = Input(shape=(6000,1))\n",
    "    conv4 = Conv1D(filters=64, kernel_size=11, activation='relu')(inputs4)\n",
    "    drop4 = Dropout(dropout)(conv4)\n",
    "    pool4 = MaxPooling1D(pool_size=2)(drop4)\n",
    "    flat4 = Flatten()(pool4)\n",
    "#     merge\n",
    "    merged = concatenate([ flat1,flat3,flat4])\n",
    "    # interpretation\n",
    "    dense1 = Dense(n_dense, activation='relu')(merged)\n",
    "    drop5 = Dropout(0.2)(dense1)\n",
    "    dense2 = Dense(n_dense, activation='relu')(drop5)\n",
    "    outputs = Dense(1, activation='sigmoid')(dense2)\n",
    "    model = Model(inputs=[inputs1,inputs3,inputs4], outputs=outputs)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "15dfb4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "# # head 1\n",
    "# inputs1 = Input(shape=(6000,1))\n",
    "# conv1 = Conv1D(filters=64, kernel_size=3, activation='relu')(inputs1)\n",
    "# drop1 = Dropout(0.5)(conv1)\n",
    "# pool1 = MaxPooling1D(pool_size=2)(drop1)\n",
    "# flat1 = Flatten()(pool1)\n",
    "# # head 2\n",
    "# inputs2 = Input(shape=(6000,1))\n",
    "# conv2 = Conv1D(filters=64, kernel_size=5, activation='relu')(inputs2)\n",
    "# drop2 = Dropout(0.5)(conv2)\n",
    "# pool2 = MaxPooling1D(pool_size=2)(drop2)\n",
    "# flat2 = Flatten()(pool2)\n",
    "# # head 3\n",
    "# inputs3 = Input(shape=(6000,1))\n",
    "# conv3 = Conv1D(filters=64, kernel_size=11, activation='relu')(inputs3)\n",
    "# drop3 = Dropout(0.5)(conv3)\n",
    "# pool3 = MaxPooling1D(pool_size=2)(drop3)\n",
    "# flat3 = Flatten()(pool3)\n",
    "# # merge\n",
    "# merged = concatenate([flat1, flat2, flat3])\n",
    "# # interpretation\n",
    "# dense1 = Dense(100, activation='relu')(merged)\n",
    "# outputs = Dense(1, activation='sigmoid')(dense1)\n",
    "# model = Model(inputs=[inputs1, inputs2, inputs3], outputs=outputs)\n",
    "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# plot_model(model, show_shapes=True, to_file='multichannel.png')\n",
    "\n",
    "# model.fit([X_train,X_train,X_train], y_train, epochs=10, batch_size=50, verbose=1)\n",
    "# _, accuracy = model.evaluate([X_test,X_test,X_test], y_test, batch_size=10, verbose=0)\n",
    "# print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5b4815ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import keras\n",
    "# model = KerasClassifier(build_fn=create_model, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e1e19714",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Fold 1 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 4s 13ms/step - loss: 5.6452 - accuracy: 0.5476\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.8694 - accuracy: 0.4881\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6454 - accuracy: 0.6667\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5847 - accuracy: 0.6786\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5471 - accuracy: 0.7024\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3985 - accuracy: 0.7857\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3210 - accuracy: 0.8690\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3082 - accuracy: 0.9048\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.0246 - accuracy: 1.0000\n",
      "Running Fold 2 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 6.3032 - accuracy: 0.5238\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.8304 - accuracy: 0.5833\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.8574 - accuracy: 0.4524\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6722 - accuracy: 0.6429\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.7711 - accuracy: 0.5595\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4860 - accuracy: 0.7619\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3983 - accuracy: 0.8214\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3362 - accuracy: 0.8690\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.5091 - accuracy: 1.0000\n",
      "Running Fold 3 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 6.8879 - accuracy: 0.5714\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 1.0937 - accuracy: 0.5833\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.8694 - accuracy: 0.6667\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5337 - accuracy: 0.7143\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4596 - accuracy: 0.7738\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5283 - accuracy: 0.8333\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3649 - accuracy: 0.8810\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6380 - accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.5641 - accuracy: 1.0000\n",
      "Running Fold 4 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 4.6081 - accuracy: 0.4762\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.7573 - accuracy: 0.5119\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6534 - accuracy: 0.7024\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6875 - accuracy: 0.6905\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5841 - accuracy: 0.7262\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4757 - accuracy: 0.8452\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5337 - accuracy: 0.7500\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4572 - accuracy: 0.8452\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.1740 - accuracy: 1.0000\n",
      "Running Fold 5 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 4.0680 - accuracy: 0.4643\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.7597 - accuracy: 0.4881\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5859 - accuracy: 0.7381\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.8774 - accuracy: 0.6429\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5844 - accuracy: 0.6786\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5627 - accuracy: 0.7738\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4246 - accuracy: 0.7976\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3045 - accuracy: 0.8333\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x00000272EE92A1F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.6599 - accuracy: 1.0000\n",
      "Running Fold 6 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 5.7222 - accuracy: 0.4405\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.7802 - accuracy: 0.5595\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6205 - accuracy: 0.6548\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4783 - accuracy: 0.7500\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6399 - accuracy: 0.7024\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3899 - accuracy: 0.8571\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3178 - accuracy: 0.8810\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.2306 - accuracy: 0.9048\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x000002744C676F70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.2611 - accuracy: 1.0000\n",
      "Running Fold 7 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 9.6979 - accuracy: 0.4405\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 1.0278 - accuracy: 0.5238\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.8142 - accuracy: 0.6310\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.7750 - accuracy: 0.6190\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5702 - accuracy: 0.7500\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5012 - accuracy: 0.7500\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5091 - accuracy: 0.7738\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3404 - accuracy: 0.8690\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.5117 - accuracy: 1.0000\n",
      "Running Fold 8 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 6.5905 - accuracy: 0.6190\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 1.1327 - accuracy: 0.4881\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.7713 - accuracy: 0.5476\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.7083 - accuracy: 0.5952\n",
      "Epoch 5/8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5859 - accuracy: 0.6667\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6413 - accuracy: 0.6667\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6982 - accuracy: 0.6071\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4875 - accuracy: 0.7619\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.0766 - accuracy: 1.0000\n",
      "Running Fold 9 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 3.1643 - accuracy: 0.6429\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.8623 - accuracy: 0.4762\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.7169 - accuracy: 0.5714\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6567 - accuracy: 0.6786\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.7812 - accuracy: 0.7024\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6287 - accuracy: 0.7857\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5932 - accuracy: 0.6786\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4573 - accuracy: 0.8214\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.1775 - accuracy: 1.0000\n",
      "Running Fold 10 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 4.5377 - accuracy: 0.4881\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.8062 - accuracy: 0.6071\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6753 - accuracy: 0.6548\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5860 - accuracy: 0.7143\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5664 - accuracy: 0.7381\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4700 - accuracy: 0.7976\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.8975 - accuracy: 0.5952\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4243 - accuracy: 0.8095\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.9591 - accuracy: 0.0000e+00\n",
      "Running Fold 11 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 5.1252 - accuracy: 0.5357\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.8338 - accuracy: 0.5238\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6785 - accuracy: 0.6071\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.7227 - accuracy: 0.7024\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5483 - accuracy: 0.7262\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6287 - accuracy: 0.7143\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6537 - accuracy: 0.8095\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3735 - accuracy: 0.9048\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.5923 - accuracy: 1.0000\n",
      "Running Fold 12 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 5.0537 - accuracy: 0.3929\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.7808 - accuracy: 0.6667\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.7394 - accuracy: 0.6190\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5545 - accuracy: 0.7262\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4795 - accuracy: 0.7143\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3693 - accuracy: 0.8810\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.2404 - accuracy: 0.9405\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.2583 - accuracy: 0.8810\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 1.5620 - accuracy: 0.0000e+00\n",
      "Running Fold 13 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 4.5856 - accuracy: 0.5119\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.7191 - accuracy: 0.5833\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.7858 - accuracy: 0.5357\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5309 - accuracy: 0.7619\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6378 - accuracy: 0.6905\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3804 - accuracy: 0.8571\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.2499 - accuracy: 0.9286\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.2908 - accuracy: 0.8571\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Running Fold 14 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 7.0715 - accuracy: 0.5238\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 1.0241 - accuracy: 0.5952\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6354 - accuracy: 0.6310\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4978 - accuracy: 0.7738\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5527 - accuracy: 0.7143\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.2743 - accuracy: 0.9167\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.1933 - accuracy: 0.9286\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3393 - accuracy: 0.8690\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.3935 - accuracy: 1.0000\n",
      "Running Fold 15 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 6.4568 - accuracy: 0.4643\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.8416 - accuracy: 0.5714\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.7422 - accuracy: 0.6548\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.7477 - accuracy: 0.6190\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4435 - accuracy: 0.8333\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3769 - accuracy: 0.8571\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3599 - accuracy: 0.8452\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3206 - accuracy: 0.8810\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 1.6724 - accuracy: 0.0000e+00\n",
      "Running Fold 16 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 6.2758 - accuracy: 0.5357\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.8664 - accuracy: 0.5595\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.7626 - accuracy: 0.5476\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6275 - accuracy: 0.6667\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.7081 - accuracy: 0.7143\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.7595 - accuracy: 0.8333\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5351 - accuracy: 0.7976\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3536 - accuracy: 0.8571\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.4247 - accuracy: 1.0000\n",
      "Running Fold 17 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 15ms/step - loss: 5.1090 - accuracy: 0.5000\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 1.0033 - accuracy: 0.4762\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.7602 - accuracy: 0.5833\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.7411 - accuracy: 0.6667\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6093 - accuracy: 0.6786\n",
      "Epoch 6/8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4636 - accuracy: 0.7738\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3123 - accuracy: 0.8571\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4251 - accuracy: 0.9048\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 6.1915 - accuracy: 0.0000e+00\n",
      "Running Fold 18 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 5.4044 - accuracy: 0.4881\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 1.0764 - accuracy: 0.5833\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.7202 - accuracy: 0.6071\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5157 - accuracy: 0.7619\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4443 - accuracy: 0.8214\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3702 - accuracy: 0.8333\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5856 - accuracy: 0.7976\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3330 - accuracy: 0.8690\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.0579 - accuracy: 1.0000\n",
      "Running Fold 19 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 5.6692 - accuracy: 0.5119\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.8330 - accuracy: 0.5833\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.7127 - accuracy: 0.6548\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5793 - accuracy: 0.6905\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.7083 - accuracy: 0.6786\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4503 - accuracy: 0.8214\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5657 - accuracy: 0.7738\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3473 - accuracy: 0.8452\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.2775 - accuracy: 1.0000\n",
      "Running Fold 20 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 6.5759 - accuracy: 0.5595\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.8339 - accuracy: 0.5595\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.7629 - accuracy: 0.5595\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.8521 - accuracy: 0.4762\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6456 - accuracy: 0.6190\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5626 - accuracy: 0.7143\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4999 - accuracy: 0.7976\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.7991 - accuracy: 0.7024\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.8553 - accuracy: 0.0000e+00\n",
      "Running Fold 21 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 5.6340 - accuracy: 0.5476\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 1.0096 - accuracy: 0.5357\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6533 - accuracy: 0.5952\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6075 - accuracy: 0.7143\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6468 - accuracy: 0.6786\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6791 - accuracy: 0.6310\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5075 - accuracy: 0.7619\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4321 - accuracy: 0.7738\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.3519 - accuracy: 1.0000\n",
      "Running Fold 22 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 6.2658 - accuracy: 0.4643\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 1.0715 - accuracy: 0.5357\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.9300 - accuracy: 0.5476\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.7542 - accuracy: 0.5238\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.7444 - accuracy: 0.4405\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6777 - accuracy: 0.6548\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6975 - accuracy: 0.6429\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5918 - accuracy: 0.6905\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 1.6071 - accuracy: 0.0000e+00\n",
      "Running Fold 23 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 3.9341 - accuracy: 0.5357\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.8154 - accuracy: 0.4881\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.7645 - accuracy: 0.5357\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6138 - accuracy: 0.6905\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5374 - accuracy: 0.7381\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4897 - accuracy: 0.7500\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6076 - accuracy: 0.7857\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4576 - accuracy: 0.7857\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Running Fold 24 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 6.9258 - accuracy: 0.5000\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.9744 - accuracy: 0.5357\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5552 - accuracy: 0.7619\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6669 - accuracy: 0.6905\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4001 - accuracy: 0.8452\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.2593 - accuracy: 0.9048\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.2322 - accuracy: 0.9048\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3382 - accuracy: 0.8810\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.2262 - accuracy: 1.0000\n",
      "Running Fold 25 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 3.9420 - accuracy: 0.5357\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.8358 - accuracy: 0.5476\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6552 - accuracy: 0.7024\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6959 - accuracy: 0.7857\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6720 - accuracy: 0.6667\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6165 - accuracy: 0.7500\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3535 - accuracy: 0.8810\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5664 - accuracy: 0.7976\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 3.2473 - accuracy: 0.0000e+00\n",
      "Running Fold 26 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 3.4749 - accuracy: 0.4643\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.9210 - accuracy: 0.5595\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6007 - accuracy: 0.6905\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6465 - accuracy: 0.6905\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5663 - accuracy: 0.7619\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3723 - accuracy: 0.8333\n",
      "Epoch 7/8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4775 - accuracy: 0.7976\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.2131 - accuracy: 0.9286\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.5442 - accuracy: 1.0000\n",
      "Running Fold 27 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 4.6947 - accuracy: 0.4762\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.8080 - accuracy: 0.6190\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.8148 - accuracy: 0.6429\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5626 - accuracy: 0.7619\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.7628 - accuracy: 0.7381\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5056 - accuracy: 0.7381\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3684 - accuracy: 0.8095\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.2677 - accuracy: 0.9048\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 3.4423 - accuracy: 0.0000e+00\n",
      "Running Fold 28 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 9.7471 - accuracy: 0.4167\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6749 - accuracy: 0.6548\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.7116 - accuracy: 0.6667\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5071 - accuracy: 0.7857\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5337 - accuracy: 0.7619\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3479 - accuracy: 0.8690\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3228 - accuracy: 0.8214\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.1565 - accuracy: 0.9762\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.4963 - accuracy: 1.0000\n",
      "Running Fold 29 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 3.3755 - accuracy: 0.5238\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6499 - accuracy: 0.6667\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6678 - accuracy: 0.7024\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4934 - accuracy: 0.7976\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4127 - accuracy: 0.8333\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4764 - accuracy: 0.7976\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3589 - accuracy: 0.8214\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3184 - accuracy: 0.8690\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 1.1078 - accuracy: 0.0000e+00\n",
      "Running Fold 30 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 9.6291 - accuracy: 0.5000\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 1.1271 - accuracy: 0.5357\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6571 - accuracy: 0.6190\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.8144 - accuracy: 0.5714\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5499 - accuracy: 0.7024\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5237 - accuracy: 0.7262\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4735 - accuracy: 0.7857\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4872 - accuracy: 0.7976\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 1.4541 - accuracy: 0.0000e+00\n",
      "Running Fold 31 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 4.1051 - accuracy: 0.4048\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6823 - accuracy: 0.6190\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5703 - accuracy: 0.7262\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5585 - accuracy: 0.6905\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4054 - accuracy: 0.8333\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3161 - accuracy: 0.8571\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5881 - accuracy: 0.8571\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3277 - accuracy: 0.9405\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.0463 - accuracy: 1.0000\n",
      "Running Fold 32 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 5.1528 - accuracy: 0.4881\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.7463 - accuracy: 0.5238\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.8790 - accuracy: 0.5238\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6579 - accuracy: 0.6667\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6567 - accuracy: 0.6548\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5898 - accuracy: 0.7857\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5445 - accuracy: 0.7500\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4794 - accuracy: 0.8214\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.6420 - accuracy: 1.0000\n",
      "Running Fold 33 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 15.4548 - accuracy: 0.5476\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 1.5683 - accuracy: 0.5238\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6566 - accuracy: 0.6667\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5808 - accuracy: 0.7262\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.7022 - accuracy: 0.6786\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6557 - accuracy: 0.6548\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3964 - accuracy: 0.8214\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4301 - accuracy: 0.8571\n",
      "1/1 [==============================] - 0s 298ms/step - loss: 0.2611 - accuracy: 1.0000\n",
      "Running Fold 34 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 4.5648 - accuracy: 0.4881\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 1.4476 - accuracy: 0.5357\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6698 - accuracy: 0.6071\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6955 - accuracy: 0.5833\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6134 - accuracy: 0.6786\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5011 - accuracy: 0.7976\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4505 - accuracy: 0.7976\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4499 - accuracy: 0.7976\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.2116 - accuracy: 1.0000\n",
      "Running Fold 35 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 2.7307 - accuracy: 0.4762\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6489 - accuracy: 0.6548\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4987 - accuracy: 0.7857\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3365 - accuracy: 0.8571\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.2133 - accuracy: 0.9286\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5560 - accuracy: 0.8333\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.2421 - accuracy: 0.9048\n",
      "Epoch 8/8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 1s 13ms/step - loss: 0.0707 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.0527 - accuracy: 1.0000\n",
      "Running Fold 36 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 4.9808 - accuracy: 0.4643\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.8940 - accuracy: 0.5714\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5482 - accuracy: 0.7262\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6432 - accuracy: 0.7024\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5613 - accuracy: 0.8452\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5122 - accuracy: 0.7976\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.2876 - accuracy: 0.8929\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.1681 - accuracy: 0.9286\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.7848 - accuracy: 0.0000e+00\n",
      "Running Fold 37 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 4.4461 - accuracy: 0.5119\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.7901 - accuracy: 0.6310\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.7445 - accuracy: 0.6310\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5496 - accuracy: 0.7857\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5156 - accuracy: 0.7143\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4342 - accuracy: 0.8690\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4807 - accuracy: 0.8333\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3931 - accuracy: 0.8214\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.2045 - accuracy: 1.0000\n",
      "Running Fold 38 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 8.5481 - accuracy: 0.5357\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.8356 - accuracy: 0.5000\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.8406 - accuracy: 0.5952\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.7039 - accuracy: 0.6190\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4822 - accuracy: 0.7619\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4371 - accuracy: 0.8095\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3075 - accuracy: 0.8929\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3116 - accuracy: 0.8452\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.0146 - accuracy: 1.0000\n",
      "Running Fold 39 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 9.6522 - accuracy: 0.5952\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 1.2014 - accuracy: 0.5476\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.7464 - accuracy: 0.7143\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4829 - accuracy: 0.7857\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5579 - accuracy: 0.8095\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5236 - accuracy: 0.7381\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3978 - accuracy: 0.8333\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.1431 - accuracy: 0.9643\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 1.1148 - accuracy: 0.0000e+00\n",
      "Running Fold 40 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 7.2492 - accuracy: 0.6190\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.8196 - accuracy: 0.6190\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6318 - accuracy: 0.6667\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5990 - accuracy: 0.7143\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4856 - accuracy: 0.7738\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5663 - accuracy: 0.7381\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4052 - accuracy: 0.8095\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.2537 - accuracy: 0.9048\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 2.6568 - accuracy: 0.0000e+00\n",
      "Running Fold 41 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 6.5297 - accuracy: 0.5357\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.7604 - accuracy: 0.5714\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.7849 - accuracy: 0.6310\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6474 - accuracy: 0.6667\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5140 - accuracy: 0.8095\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3837 - accuracy: 0.8690\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4138 - accuracy: 0.8452\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3338 - accuracy: 0.8690\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.7629 - accuracy: 0.0000e+00\n",
      "Running Fold 42 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 6.5836 - accuracy: 0.4286\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.8120 - accuracy: 0.5357\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6328 - accuracy: 0.6667\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.9197 - accuracy: 0.5595\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5668 - accuracy: 0.7619\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4704 - accuracy: 0.8690\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4265 - accuracy: 0.8095\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4777 - accuracy: 0.8214\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.1455 - accuracy: 1.0000\n",
      "Running Fold 43 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 6.7930 - accuracy: 0.3214\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.9083 - accuracy: 0.5595\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6982 - accuracy: 0.6667\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5778 - accuracy: 0.7262\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4746 - accuracy: 0.7857\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3717 - accuracy: 0.8333\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.2346 - accuracy: 0.9286\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.1612 - accuracy: 0.9405\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 1.7467 - accuracy: 0.0000e+00\n",
      "Running Fold 44 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 3.2520 - accuracy: 0.4167\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6947 - accuracy: 0.5476\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5893 - accuracy: 0.6905\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5479 - accuracy: 0.7500\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6387 - accuracy: 0.6548\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6529 - accuracy: 0.7738\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5632 - accuracy: 0.7381\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4757 - accuracy: 0.7619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 172ms/step - loss: 4.5361 - accuracy: 0.0000e+00\n",
      "Running Fold 45 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 4.9052 - accuracy: 0.4167\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.7823 - accuracy: 0.5357\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6425 - accuracy: 0.6905\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5530 - accuracy: 0.7262\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3848 - accuracy: 0.8333\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3075 - accuracy: 0.8929\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3981 - accuracy: 0.8333\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.1872 - accuracy: 0.9524\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.4964 - accuracy: 1.0000\n",
      "Running Fold 46 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 5.5934 - accuracy: 0.5357\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 1.0461 - accuracy: 0.5833\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6594 - accuracy: 0.6548\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6080 - accuracy: 0.6786\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6432 - accuracy: 0.7143\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5546 - accuracy: 0.7500\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5508 - accuracy: 0.7024\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4284 - accuracy: 0.7976\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 2.0370 - accuracy: 0.0000e+00\n",
      "Running Fold 47 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 3.2212 - accuracy: 0.4167\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6627 - accuracy: 0.6310\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5622 - accuracy: 0.7381\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5069 - accuracy: 0.7381\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4454 - accuracy: 0.8333\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3392 - accuracy: 0.8690\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.2309 - accuracy: 0.9524\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.2232 - accuracy: 0.9048\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 2.5754 - accuracy: 0.0000e+00\n",
      "Running Fold 48 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 5.1987 - accuracy: 0.4643\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.7082 - accuracy: 0.5357\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6664 - accuracy: 0.6905\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6434 - accuracy: 0.6905\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5698 - accuracy: 0.7500\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4716 - accuracy: 0.7738\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3058 - accuracy: 0.8571\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3118 - accuracy: 0.9048\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.5652 - accuracy: 1.0000\n",
      "Running Fold 49 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 5.0677 - accuracy: 0.5119\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.9123 - accuracy: 0.6071\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.7616 - accuracy: 0.5833\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6380 - accuracy: 0.7381\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5939 - accuracy: 0.6905\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4790 - accuracy: 0.7738\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6159 - accuracy: 0.6667\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6003 - accuracy: 0.7976\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 1.7666 - accuracy: 0.0000e+00\n",
      "Running Fold 50 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 6.4286 - accuracy: 0.4405\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.9522 - accuracy: 0.5000\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.9194 - accuracy: 0.5952\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.7911 - accuracy: 0.6786\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5533 - accuracy: 0.6905\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5510 - accuracy: 0.7738\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3369 - accuracy: 0.8452\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.2325 - accuracy: 0.9286\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 1.6042 - accuracy: 0.0000e+00\n",
      "Running Fold 51 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 4.9931 - accuracy: 0.4405\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6891 - accuracy: 0.6310\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6785 - accuracy: 0.6429\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5385 - accuracy: 0.7738\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4421 - accuracy: 0.8095\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3258 - accuracy: 0.8929\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4348 - accuracy: 0.8333\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3764 - accuracy: 0.8571\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Running Fold 52 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 4.4963 - accuracy: 0.4881\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6655 - accuracy: 0.6429\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6323 - accuracy: 0.7262\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5303 - accuracy: 0.7738\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5531 - accuracy: 0.7500\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.2830 - accuracy: 0.8810\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3058 - accuracy: 0.8690\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3050 - accuracy: 0.9048\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 3.1704 - accuracy: 0.0000e+00\n",
      "Running Fold 53 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 4.0753 - accuracy: 0.4524\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.7286 - accuracy: 0.5595\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6938 - accuracy: 0.6190\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6097 - accuracy: 0.7500\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5729 - accuracy: 0.7619\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6369 - accuracy: 0.6786\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3735 - accuracy: 0.9048\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3799 - accuracy: 0.8571\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 1.7879 - accuracy: 0.0000e+00\n",
      "Running Fold 54 / 85\n",
      "Epoch 1/8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 2s 13ms/step - loss: 6.2883 - accuracy: 0.4524\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.8604 - accuracy: 0.5595\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5400 - accuracy: 0.7381\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5317 - accuracy: 0.7262\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4807 - accuracy: 0.7857\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3240 - accuracy: 0.8929\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3391 - accuracy: 0.8333\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.2974 - accuracy: 0.8929\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 1.6221 - accuracy: 0.0000e+00\n",
      "Running Fold 55 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 3.3809 - accuracy: 0.4643\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.7451 - accuracy: 0.5833\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6497 - accuracy: 0.6548\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4479 - accuracy: 0.7857\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3060 - accuracy: 0.9167\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.2042 - accuracy: 0.9167\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3874 - accuracy: 0.8810\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.1178 - accuracy: 0.9524\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.9531 - accuracy: 0.0000e+00\n",
      "Running Fold 56 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 6.6582 - accuracy: 0.5000\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 1.1623 - accuracy: 0.4881\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6844 - accuracy: 0.6905\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 0.7155 - accuracy: 0.5357\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6250 - accuracy: 0.7143\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4569 - accuracy: 0.8333\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4290 - accuracy: 0.8333\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4506 - accuracy: 0.8452\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 1.8136 - accuracy: 0.0000e+00\n",
      "Running Fold 57 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 4.7890 - accuracy: 0.4524\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.7749 - accuracy: 0.5595\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.7474 - accuracy: 0.6071\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5460 - accuracy: 0.7262\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6527 - accuracy: 0.6905\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4011 - accuracy: 0.7857\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3620 - accuracy: 0.8690\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4062 - accuracy: 0.7976\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.0140 - accuracy: 1.0000\n",
      "Running Fold 58 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 5.6292 - accuracy: 0.3333\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6397 - accuracy: 0.6190\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6781 - accuracy: 0.7024\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.7602 - accuracy: 0.7024\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5395 - accuracy: 0.7619\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3559 - accuracy: 0.8452\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4611 - accuracy: 0.7976\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.2233 - accuracy: 0.9405\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.4901 - accuracy: 1.0000\n",
      "Running Fold 59 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 6.2831 - accuracy: 0.4881\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.9969 - accuracy: 0.5119\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 0.5507 - accuracy: 0.6548\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.8322 - accuracy: 0.5952\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.7780 - accuracy: 0.7976\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4583 - accuracy: 0.8214\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3717 - accuracy: 0.8333\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4808 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.0574 - accuracy: 1.0000\n",
      "Running Fold 60 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 4.2089 - accuracy: 0.4881\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.8114 - accuracy: 0.5952\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.7150 - accuracy: 0.6071\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.7341 - accuracy: 0.5952\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6000 - accuracy: 0.6548\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5067 - accuracy: 0.8214\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4523 - accuracy: 0.7976\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4184 - accuracy: 0.9167\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 0.0532 - accuracy: 1.0000\n",
      "Running Fold 61 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 6.6176 - accuracy: 0.4405\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.8503 - accuracy: 0.5000\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.7137 - accuracy: 0.6310\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5699 - accuracy: 0.7024\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4655 - accuracy: 0.7857\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5341 - accuracy: 0.7381\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3647 - accuracy: 0.8690\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.2218 - accuracy: 0.9048\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.2692 - accuracy: 1.0000\n",
      "Running Fold 62 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 5.0251 - accuracy: 0.4643\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 1.0051 - accuracy: 0.5357\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6455 - accuracy: 0.6310\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5747 - accuracy: 0.7619\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4918 - accuracy: 0.7857\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3910 - accuracy: 0.8095\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.2704 - accuracy: 0.9048\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 0.2183 - accuracy: 0.9524\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 1.1583 - accuracy: 0.0000e+00\n",
      "Running Fold 63 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 3.0627 - accuracy: 0.5357\n",
      "Epoch 2/8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 1s 13ms/step - loss: 1.0464 - accuracy: 0.5476\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6649 - accuracy: 0.6310\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.8623 - accuracy: 0.7024\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.7871 - accuracy: 0.6786\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4269 - accuracy: 0.8095\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3662 - accuracy: 0.8571\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.2653 - accuracy: 0.8929\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.4748 - accuracy: 1.0000\n",
      "Running Fold 64 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 4.8043 - accuracy: 0.5119\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.7058 - accuracy: 0.5595\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 0.6897 - accuracy: 0.5595\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5988 - accuracy: 0.6905\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4949 - accuracy: 0.7381\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.7301 - accuracy: 0.6905\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4798 - accuracy: 0.7738\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3032 - accuracy: 0.8690\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.1253 - accuracy: 1.0000\n",
      "Running Fold 65 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 5.5408 - accuracy: 0.4167\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.9212 - accuracy: 0.5238\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6843 - accuracy: 0.6190\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6272 - accuracy: 0.7024\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4589 - accuracy: 0.8214\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4167 - accuracy: 0.7976\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6300 - accuracy: 0.7500\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.2792 - accuracy: 0.8810\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.0066 - accuracy: 1.0000\n",
      "Running Fold 66 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 4.4365 - accuracy: 0.4286\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6702 - accuracy: 0.6190\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5640 - accuracy: 0.7262\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5259 - accuracy: 0.7500\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3075 - accuracy: 0.8452\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.8272 - accuracy: 0.6667\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6465 - accuracy: 0.7381\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.2760 - accuracy: 0.9286\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.2542 - accuracy: 1.0000\n",
      "Running Fold 67 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 6.1866 - accuracy: 0.4643\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.7694 - accuracy: 0.5714\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6253 - accuracy: 0.7381\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5021 - accuracy: 0.7619\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5128 - accuracy: 0.8571\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3954 - accuracy: 0.8452\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3729 - accuracy: 0.8214\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4113 - accuracy: 0.8095\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.0128 - accuracy: 1.0000\n",
      "Running Fold 68 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 7.3330 - accuracy: 0.4762\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.7819 - accuracy: 0.6548\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5942 - accuracy: 0.6905\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5432 - accuracy: 0.7500\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5518 - accuracy: 0.8095\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3379 - accuracy: 0.8929\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.1696 - accuracy: 0.9643\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.1183 - accuracy: 0.9762\n",
      "1/1 [==============================] - 0s 305ms/step - loss: 1.4500 - accuracy: 0.0000e+00\n",
      "Running Fold 69 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 5.9729 - accuracy: 0.3810\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.7451 - accuracy: 0.5000\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.7003 - accuracy: 0.5952\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6574 - accuracy: 0.6786\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4541 - accuracy: 0.8095\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4194 - accuracy: 0.8214\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.2859 - accuracy: 0.9048\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.1849 - accuracy: 0.9048\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.0491 - accuracy: 1.0000\n",
      "Running Fold 70 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 6.8123 - accuracy: 0.3929\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.7887 - accuracy: 0.6190\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6758 - accuracy: 0.6667\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6512 - accuracy: 0.6667\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4993 - accuracy: 0.7857\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4517 - accuracy: 0.7857\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4842 - accuracy: 0.7857\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3616 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 1.5096 - accuracy: 0.0000e+00\n",
      "Running Fold 71 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 7.6591 - accuracy: 0.5714\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.8799 - accuracy: 0.4762\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.7239 - accuracy: 0.6786\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6359 - accuracy: 0.6429\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5594 - accuracy: 0.6905\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4421 - accuracy: 0.7976\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3619 - accuracy: 0.8571\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3151 - accuracy: 0.8690\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 3.2238 - accuracy: 0.0000e+00\n",
      "Running Fold 72 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 4.1051 - accuracy: 0.4881\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.9429 - accuracy: 0.5714\n",
      "Epoch 3/8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6943 - accuracy: 0.5595\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6058 - accuracy: 0.6905\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6485 - accuracy: 0.6905\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4822 - accuracy: 0.8095\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5641 - accuracy: 0.7619\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3494 - accuracy: 0.8690\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.5532 - accuracy: 1.0000\n",
      "Running Fold 73 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 3.7465 - accuracy: 0.4881\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.8119 - accuracy: 0.5119\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6704 - accuracy: 0.6667\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5817 - accuracy: 0.7143\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4806 - accuracy: 0.8452\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5531 - accuracy: 0.7619\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4481 - accuracy: 0.8095\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4343 - accuracy: 0.8214\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 1.9198 - accuracy: 0.0000e+00\n",
      "Running Fold 74 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 6.8705 - accuracy: 0.5238\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.9714 - accuracy: 0.6548\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5783 - accuracy: 0.6905\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4795 - accuracy: 0.8095\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4396 - accuracy: 0.7500\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.2783 - accuracy: 0.8929\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.1855 - accuracy: 0.9405\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4034 - accuracy: 0.7738\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.6643 - accuracy: 1.0000\n",
      "Running Fold 75 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 4.8362 - accuracy: 0.3810\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.7900 - accuracy: 0.6548\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5708 - accuracy: 0.7262\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5252 - accuracy: 0.7619\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3217 - accuracy: 0.9167\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6242 - accuracy: 0.7143\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.2384 - accuracy: 0.9286\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.1565 - accuracy: 0.9405\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 4.4152 - accuracy: 0.0000e+00\n",
      "Running Fold 76 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 12.8295 - accuracy: 0.4167\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 1.2318 - accuracy: 0.5476\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.9624 - accuracy: 0.5238\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6349 - accuracy: 0.6310\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5773 - accuracy: 0.6905\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4710 - accuracy: 0.7500\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5020 - accuracy: 0.7738\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3617 - accuracy: 0.8810\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 2.0560 - accuracy: 0.0000e+00\n",
      "Running Fold 77 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 3.3707 - accuracy: 0.5595\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.8250 - accuracy: 0.5357\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6244 - accuracy: 0.6786\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6812 - accuracy: 0.6190\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.7839 - accuracy: 0.6548\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6993 - accuracy: 0.6190\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4081 - accuracy: 0.8690\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.2583 - accuracy: 0.9167\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.0481 - accuracy: 1.0000\n",
      "Running Fold 78 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 6.7320 - accuracy: 0.4643\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.7303 - accuracy: 0.6429\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.7278 - accuracy: 0.5714\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.7004 - accuracy: 0.6190\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6240 - accuracy: 0.7143\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.7239 - accuracy: 0.6429\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4345 - accuracy: 0.7857\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4148 - accuracy: 0.7857\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 1.1901 - accuracy: 0.0000e+00\n",
      "Running Fold 79 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 8.5634 - accuracy: 0.3690\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 1.0894 - accuracy: 0.5238\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.9087 - accuracy: 0.5357\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6902 - accuracy: 0.6667\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.7324 - accuracy: 0.6548\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5507 - accuracy: 0.7262\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5083 - accuracy: 0.7738\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5910 - accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Running Fold 80 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 6.2462 - accuracy: 0.4286\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6703 - accuracy: 0.5595\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6925 - accuracy: 0.6310\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6181 - accuracy: 0.6548\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4451 - accuracy: 0.8333\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4733 - accuracy: 0.8452\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3046 - accuracy: 0.9048\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3004 - accuracy: 0.8929\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.7911 - accuracy: 0.0000e+00\n",
      "Running Fold 81 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 2.3166 - accuracy: 0.4881\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.7463 - accuracy: 0.5476\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.9027 - accuracy: 0.5714\n",
      "Epoch 4/8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6039 - accuracy: 0.6071\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6824 - accuracy: 0.6310\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5147 - accuracy: 0.7381\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5622 - accuracy: 0.7500\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3983 - accuracy: 0.8452\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.8051 - accuracy: 0.0000e+00\n",
      "Running Fold 82 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 3.3147 - accuracy: 0.5357\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.8728 - accuracy: 0.5476\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6592 - accuracy: 0.5952\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6386 - accuracy: 0.7262\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.8193 - accuracy: 0.6548\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4187 - accuracy: 0.7738\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4038 - accuracy: 0.8214\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5268 - accuracy: 0.8452\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.8338 - accuracy: 0.0000e+00\n",
      "Running Fold 83 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 2.8728 - accuracy: 0.5357\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.7180 - accuracy: 0.5952\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6414 - accuracy: 0.6190\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6354 - accuracy: 0.6905\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5164 - accuracy: 0.7619\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5169 - accuracy: 0.8095\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4445 - accuracy: 0.7738\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3632 - accuracy: 0.8571\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.0654 - accuracy: 1.0000\n",
      "Running Fold 84 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 6.0776 - accuracy: 0.4286\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.9093 - accuracy: 0.5357\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.8052 - accuracy: 0.5476\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.7988 - accuracy: 0.6190\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6262 - accuracy: 0.6429\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4930 - accuracy: 0.7738\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5011 - accuracy: 0.8214\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.3178 - accuracy: 0.8810\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.1630 - accuracy: 1.0000\n",
      "Running Fold 85 / 85\n",
      "Epoch 1/8\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 11.0427 - accuracy: 0.5357\n",
      "Epoch 2/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.9715 - accuracy: 0.6071\n",
      "Epoch 3/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.8165 - accuracy: 0.5833\n",
      "Epoch 4/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5340 - accuracy: 0.6786\n",
      "Epoch 5/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.5555 - accuracy: 0.7262\n",
      "Epoch 6/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.4432 - accuracy: 0.8214\n",
      "Epoch 7/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.2812 - accuracy: 0.9167\n",
      "Epoch 8/8\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.6950 - accuracy: 0.7024\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.3031 - accuracy: 1.0000\n",
      "\n",
      "Mean accuracy of the crossvalidation: 0.5764705882352941\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold\n",
    "n_folds = 85\n",
    "skf = KFold(n_folds)\n",
    "skf = skf.split(X_padded,y)\n",
    "\n",
    "cv_score = []\n",
    "\n",
    "for i, (train, test) in enumerate(skf):\n",
    "    model2 =create_model()\n",
    "    # currently keras doesn't have like model.reset(), so the easiest way\n",
    "    # recompiling our model in every step of the loop see below more\n",
    "    sc = StandardScaler()\n",
    "    sc2 = MinMaxScaler()  \n",
    "    X_train = X_padded[train]\n",
    "#     X_train = sc.fit_transform(X_train)\n",
    "    X_train = sc2.fit_transform(X_train)\n",
    "    X_train = np.array(X_train)\n",
    "    X_train = np.reshape(X_train,(X_train.shape[0],X_train.shape[1],1))\n",
    "    X_test = X_padded[test]\n",
    "#     X_test = sc.transform(X_test)\n",
    "    X_test = sc2.transform(X_test)\n",
    "    X_test = np.array(X_test)\n",
    "    X_test = np.reshape(X_test,(X_test.shape[0],X_test.shape[1],1))\n",
    "    \n",
    "    print(\"Running Fold\", i+1, \"/\", n_folds)\n",
    "    model2.fit([X_train,X_train,X_train], y[train], epochs=10, batch_size=1)\n",
    "    result = model2.evaluate([X_test,X_test,X_test], y[test])\n",
    "    keras.backend.clear_session()\n",
    "    # if we want only the accuracy metric\n",
    "    cv_score.append(result[1])\n",
    "    # we have to clear previous model to reset weights\n",
    "    # currently keras doesn't have like model.reset()\n",
    "   \n",
    "\n",
    "print(\"\\nMean accuracy of the crossvalidation: {}\".format(np.mean(cv_score),np.std(cv_score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6b239e70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4d6713fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 0.5311 - accuracy: 0.8235\n",
      "Epoch 2/5\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 0.1243 - accuracy: 0.9706\n",
      "Epoch 3/5\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 0.0439 - accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 0.0170 - accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "68/68 [==============================] - 1s 13ms/step - loss: 0.0146 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micoa\\anaconda3\\envs\\classifiertest\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function plot_roc_curve is deprecated; This will be removed in v0.5.0. Please use scikitplot.metrics.plot_roc instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\micoa\\anaconda3\\envs\\classifiertest\\lib\\site-packages\\keras\\engine\\training.py:1330 test_function  *\n        return step_function(self, iterator)\n    C:\\Users\\micoa\\anaconda3\\envs\\classifiertest\\lib\\site-packages\\keras\\engine\\training.py:1320 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\micoa\\anaconda3\\envs\\classifiertest\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\micoa\\anaconda3\\envs\\classifiertest\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\micoa\\anaconda3\\envs\\classifiertest\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\micoa\\anaconda3\\envs\\classifiertest\\lib\\site-packages\\keras\\engine\\training.py:1313 run_step  **\n        outputs = model.test_step(data)\n    C:\\Users\\micoa\\anaconda3\\envs\\classifiertest\\lib\\site-packages\\keras\\engine\\training.py:1267 test_step\n        y_pred = self(x, training=False)\n    C:\\Users\\micoa\\anaconda3\\envs\\classifiertest\\lib\\site-packages\\keras\\engine\\base_layer.py:1020 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    C:\\Users\\micoa\\anaconda3\\envs\\classifiertest\\lib\\site-packages\\keras\\engine\\input_spec.py:199 assert_input_compatibility\n        raise ValueError('Layer ' + layer_name + ' expects ' +\n\n    ValueError: Layer model expects 3 input(s), but it received 2 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 6000, 1) dtype=float32>, <tf.Tensor 'IteratorGetNext:1' shape=(None, 6000, 1) dtype=float32>]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [32]\u001b[0m, in \u001b[0;36m<cell line: 19>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m y_proba \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate((y_test_probs_minus,Y_test_probs),axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     16\u001b[0m skplt\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mplot_roc_curve(y_test, y_proba,\n\u001b[0;32m     17\u001b[0m                        title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m ROC Curve\u001b[39m\u001b[38;5;124m\"\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m,\u001b[38;5;241m6\u001b[39m));\n\u001b[1;32m---> 19\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mmodel3\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(result[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     21\u001b[0m keras\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39mclear_session()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\classifiertest\\lib\\site-packages\\keras\\engine\\training.py:1501\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m, step_num\u001b[38;5;241m=\u001b[39mstep, _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1500\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[1;32m-> 1501\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1503\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\classifiertest\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:885\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    882\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    884\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 885\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    887\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    888\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\classifiertest\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:933\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    931\u001b[0m   \u001b[38;5;66;03m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[0;32m    932\u001b[0m   initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 933\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    934\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    935\u001b[0m   \u001b[38;5;66;03m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[0;32m    936\u001b[0m   \u001b[38;5;66;03m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[0;32m    937\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\classifiertest\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:759\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    756\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph \u001b[38;5;241m=\u001b[39m lifted_initializer_graph\n\u001b[0;32m    757\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph_deleter \u001b[38;5;241m=\u001b[39m FunctionDeleter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph)\n\u001b[0;32m    758\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_stateful_fn \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 759\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn\u001b[38;5;241m.\u001b[39m_get_concrete_function_internal_garbage_collected(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    760\u001b[0m         \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds))\n\u001b[0;32m    762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[0;32m    763\u001b[0m   \u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\classifiertest\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3066\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3064\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   3065\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m-> 3066\u001b[0m   graph_function, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3067\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\classifiertest\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3463\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3459\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_define_function_with_shape_relaxation(\n\u001b[0;32m   3460\u001b[0m       args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[0;32m   3462\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39mmissed\u001b[38;5;241m.\u001b[39madd(call_context_key)\n\u001b[1;32m-> 3463\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_graph_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3464\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39mprimary[cache_key] \u001b[38;5;241m=\u001b[39m graph_function\n\u001b[0;32m   3466\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function, filtered_flat_args\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\classifiertest\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3298\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3293\u001b[0m missing_arg_names \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   3294\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (arg, i) \u001b[38;5;28;01mfor\u001b[39;00m i, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(missing_arg_names)\n\u001b[0;32m   3295\u001b[0m ]\n\u001b[0;32m   3296\u001b[0m arg_names \u001b[38;5;241m=\u001b[39m base_arg_names \u001b[38;5;241m+\u001b[39m missing_arg_names\n\u001b[0;32m   3297\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m ConcreteFunction(\n\u001b[1;32m-> 3298\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3299\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3300\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3301\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3302\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3303\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3304\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3305\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3306\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3307\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   3309\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[0;32m   3310\u001b[0m     function_spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[0;32m   3311\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[0;32m   3312\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[0;32m   3313\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[0;32m   3314\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[0;32m   3315\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   3316\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\classifiertest\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1007\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1004\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1005\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[1;32m-> 1007\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m python_func(\u001b[38;5;241m*\u001b[39mfunc_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfunc_kwargs)\n\u001b[0;32m   1009\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m   1010\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m   1011\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mmap_structure(convert, func_outputs,\n\u001b[0;32m   1012\u001b[0m                                   expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\classifiertest\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:668\u001b[0m, in \u001b[0;36mFunction._defun_with_scope.<locals>.wrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    664\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m default_graph\u001b[38;5;241m.\u001b[39m_variable_creator_scope(scope, priority\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    665\u001b[0m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[0;32m    666\u001b[0m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[0;32m    667\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[1;32m--> 668\u001b[0m     out \u001b[38;5;241m=\u001b[39m weak_wrapped_fn()\u001b[38;5;241m.\u001b[39m__wrapped__(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    669\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\classifiertest\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:994\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    992\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    993\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 994\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[0;32m    995\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    996\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\micoa\\anaconda3\\envs\\classifiertest\\lib\\site-packages\\keras\\engine\\training.py:1330 test_function  *\n        return step_function(self, iterator)\n    C:\\Users\\micoa\\anaconda3\\envs\\classifiertest\\lib\\site-packages\\keras\\engine\\training.py:1320 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\micoa\\anaconda3\\envs\\classifiertest\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\micoa\\anaconda3\\envs\\classifiertest\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\micoa\\anaconda3\\envs\\classifiertest\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\micoa\\anaconda3\\envs\\classifiertest\\lib\\site-packages\\keras\\engine\\training.py:1313 run_step  **\n        outputs = model.test_step(data)\n    C:\\Users\\micoa\\anaconda3\\envs\\classifiertest\\lib\\site-packages\\keras\\engine\\training.py:1267 test_step\n        y_pred = self(x, training=False)\n    C:\\Users\\micoa\\anaconda3\\envs\\classifiertest\\lib\\site-packages\\keras\\engine\\base_layer.py:1020 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    C:\\Users\\micoa\\anaconda3\\envs\\classifiertest\\lib\\site-packages\\keras\\engine\\input_spec.py:199 assert_input_compatibility\n        raise ValueError('Layer ' + layer_name + ' expects ' +\n\n    ValueError: Layer model expects 3 input(s), but it received 2 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 6000, 1) dtype=float32>, <tf.Tensor 'IteratorGetNext:1' shape=(None, 6000, 1) dtype=float32>]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import scikitplot as skplt\n",
    "model3 =create_model()\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_padded,y,test_size = 0.2,stratify=y)\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_train = sc2.fit_transform(X_train)\n",
    "X_train = np.array(X_train)\n",
    "X_train = np.reshape(X_train,(X_train.shape[0],X_train.shape[1],1))\n",
    "X_test = sc.transform(X_test)\n",
    "X_test = sc2.transform(X_test)\n",
    "X_test = np.array(X_test)\n",
    "X_test = np.reshape(X_test,(X_test.shape[0],X_test.shape[1],1))\n",
    "model2.fit([X_train,X_train,X_train], y_train, epochs=5, batch_size=1)\n",
    "Y_test_probs = model3.predict([X_test,X_test,X_test])\n",
    "y_test_probs_minus = [1-x for x in Y_test_probs]\n",
    "y_proba = np.concatenate((y_test_probs_minus,Y_test_probs),axis = 1)\n",
    "skplt.metrics.plot_roc_curve(y_test, y_proba,\n",
    "                       title=\" ROC Curve\", figsize=(12,6));\n",
    "\n",
    "result = model3.evaluate([X_test,X_test,X_test], y_test)\n",
    "print(result[1])\n",
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9be0b4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from keras.utils.vis_utils import plot_model\n",
    "# plot_model(model, show_shapes=True, to_file='multichannel.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4d4513",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores_total = [0.7058823704719543, 1.0, 1.0, 1.0, 1.0,1.0, 1.0, 1.0, 1.0, 1.0,1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,0.66,0.8888888955116272, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
    "print(np.mean(cv_scores_total))\n",
    "print(np.std(cv_scores_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff25d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot([cv_scores_total], notch=None, vert=None, patch_artist=None, widths=None,labels=['multiheadedcnn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622a0aa1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# param_grid={\n",
    "#         'batch_size':[10,20,30], \n",
    "#         'epochs':[20,30],\n",
    "#         'dropout':[0.3,0.4,0.5,0.6],\n",
    "#         'n_dense' :[50,100,150]\n",
    "           \n",
    "#         }\n",
    "# grid = GridSearchCV(estimator=model, param_grid=param_grid,pre_dispatch=6, cv=StratifiedKFold(5))\n",
    "# grid_result = grid.fit([X_padded,X_padded,X_padded], y)\n",
    "# print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "# means = grid_result.cv_results_['mean_test_score']\n",
    "# stds = grid_result.cv_results_['std_test_score']\n",
    "# params = grid_result.cv_results_['params']\n",
    "# for mean, stdev, param in zip(means, stds, params):\n",
    "#     print(\"%f (%f) with: %r\" % (mean, stdev, param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96baf806",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
